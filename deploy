#!/bin/bash

set -e;

# Load environment variables from .env.local if it exists
if [ -f .env.local ]; then
  source .env.local
fi

# Parse arguments
# Use ADMIN_PROFILE for deployments if available (has CloudFormation permissions)
# Otherwise fall back to AWS_PROFILE
CDK_PROFILE=${ADMIN_PROFILE:-${AWS_PROFILE:-default}}
CDK_REGION=${AWS_REGION:-us-west-2}
DEPLOYMENT_ENV=${NODE_ENV:-development}

# Export CDK_DEFAULT_ACCOUNT from AWS_ACCOUNT_ID if set
# This ensures CDK uses the correct account ID from .env.local
if [ ! -z "$AWS_ACCOUNT_ID" ]; then
  export CDK_DEFAULT_ACCOUNT=$AWS_ACCOUNT_ID
  echo "Using Account ID from .env.local: $AWS_ACCOUNT_ID"
fi

# Export CDK_DEFAULT_REGION
export CDK_DEFAULT_REGION=$CDK_REGION
while [[ "$#" -gt 0 ]]; do case $1 in
  --profile) CDK_PROFILE="$2"; shift;;
  --region) AWS_REGION="$2"; shift;;
  --env) DEPLOYMENT_ENV="$2"; shift;;
esac; shift; done

# Check if region is set
if [ -z "$AWS_REGION" ]; then
  # Try to get region from AWS config
  AWS_REGION=$(aws configure get region --profile $CDK_PROFILE 2>/dev/null)
  
  if [ -z "$AWS_REGION" ]; then
    echo "Error: AWS region is required"
    echo "Usage: ./deploy [--profile <aws_profile>] [--region <aws_region>] [--env <environment>]"
    echo "Example: ./deploy --profile dev --region us-west-2 --env development"
    echo "You may also configure your region by running 'aws configure'"
    exit 1
  fi
fi

echo "Using AWS Profile: $CDK_PROFILE"
echo "Using AWS Region: $AWS_REGION"
echo "Using Environment: $DEPLOYMENT_ENV"

# Build and deploy infrastructure
echo "Building and deploying infrastructure..."
# Skip npm ci if node_modules exists and build works (faster, avoids permission issues)
if [ ! -d "node_modules" ] || ! npm run build > /dev/null 2>&1; then
  echo "Installing dependencies..."
  npm install
fi
npm run build

# Prepare CDK context parameters
CDK_CONTEXT_PARAMS=""
CDK_CONTEXT_PARAMS="$CDK_CONTEXT_PARAMS -c nodeEnv=$DEPLOYMENT_ENV"

# Set logging level (default to info)
LOG_LEVEL=${LOG_LEVEL:-info}
CDK_CONTEXT_PARAMS="$CDK_CONTEXT_PARAMS -c logLevel=$LOG_LEVEL"

# Set defaults for S3 Buckets (optional - from .env.local)
EVIDENCE_LEDGER_BUCKET=${EVIDENCE_LEDGER_BUCKET:-}
WORLD_STATE_SNAPSHOTS_BUCKET=${WORLD_STATE_SNAPSHOTS_BUCKET:-}
SCHEMA_REGISTRY_BUCKET=${SCHEMA_REGISTRY_BUCKET:-}
ARTIFACTS_BUCKET=${ARTIFACTS_BUCKET:-}
LEDGER_ARCHIVES_BUCKET=${LEDGER_ARCHIVES_BUCKET:-}

# Pass S3 bucket names to CDK if provided
if [ ! -z "$EVIDENCE_LEDGER_BUCKET" ]; then
  CDK_CONTEXT_PARAMS="$CDK_CONTEXT_PARAMS -c evidenceLedgerBucket=$EVIDENCE_LEDGER_BUCKET"
  echo "Using Evidence Ledger Bucket: $EVIDENCE_LEDGER_BUCKET"
fi

if [ ! -z "$WORLD_STATE_SNAPSHOTS_BUCKET" ]; then
  CDK_CONTEXT_PARAMS="$CDK_CONTEXT_PARAMS -c worldStateSnapshotsBucket=$WORLD_STATE_SNAPSHOTS_BUCKET"
  echo "Using World State Snapshots Bucket: $WORLD_STATE_SNAPSHOTS_BUCKET"
fi

if [ ! -z "$SCHEMA_REGISTRY_BUCKET" ]; then
  CDK_CONTEXT_PARAMS="$CDK_CONTEXT_PARAMS -c schemaRegistryBucket=$SCHEMA_REGISTRY_BUCKET"
  echo "Using Schema Registry Bucket: $SCHEMA_REGISTRY_BUCKET"
fi

if [ ! -z "$ARTIFACTS_BUCKET" ]; then
  CDK_CONTEXT_PARAMS="$CDK_CONTEXT_PARAMS -c artifactsBucket=$ARTIFACTS_BUCKET"
  echo "Using Artifacts Bucket: $ARTIFACTS_BUCKET"
fi

if [ ! -z "$LEDGER_ARCHIVES_BUCKET" ]; then
  CDK_CONTEXT_PARAMS="$CDK_CONTEXT_PARAMS -c ledgerArchivesBucket=$LEDGER_ARCHIVES_BUCKET"
  echo "Using Ledger Archives Bucket: $LEDGER_ARCHIVES_BUCKET"
fi

echo "Using Log Level: $LOG_LEVEL"

# Find existing stack
echo "Finding existing CC Native stack..."
STACK_NAME=$(aws cloudformation list-stacks \
  --profile $CDK_PROFILE \
  --region $AWS_REGION \
  --no-cli-pager \
  --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE UPDATE_ROLLBACK_COMPLETE \
  --query "StackSummaries[?starts_with(StackName, 'CCNativeStack')].StackName" \
  --output text | head -n 1)

if [ -z "$STACK_NAME" ]; then
  echo "No existing CC Native stack found. Creating new stack..."
  npx cdk --profile $CDK_PROFILE --region $AWS_REGION deploy CCNativeStack --require-approval never $CDK_CONTEXT_PARAMS
else
  echo "Updating existing stack: $STACK_NAME"
  npx cdk --profile $CDK_PROFILE --region $AWS_REGION deploy CCNativeStack --require-approval never $CDK_CONTEXT_PARAMS
fi

# Get stack outputs
echo "Getting stack outputs..."
STACK_OUTPUTS=$(aws cloudformation describe-stacks \
  --profile $CDK_PROFILE \
  --region $AWS_REGION \
  --no-cli-pager \
  --stack-name CCNativeStack \
  --query 'Stacks[0].Outputs' \
  --output json)

# Extract output values (use stack outputs, or fall back to .env.local if provided)
EVIDENCE_LEDGER_BUCKET_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="EvidenceLedgerBucketName") | .OutputValue')
WORLD_STATE_SNAPSHOTS_BUCKET_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="WorldStateSnapshotsBucketName") | .OutputValue')
SCHEMA_REGISTRY_BUCKET_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="SchemaRegistryBucketName") | .OutputValue')
ARTIFACTS_BUCKET_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="ArtifactsBucketName") | .OutputValue')
LEDGER_ARCHIVES_BUCKET_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="LedgerArchivesBucketName") | .OutputValue')
EVENT_BUS_NAME=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="EventBusName") | .OutputValue')

# Extract DynamoDB table names from stack outputs
WORLD_STATE_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="WorldStateTableName") | .OutputValue')
EVIDENCE_INDEX_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="EvidenceIndexTableName") | .OutputValue')
SNAPSHOTS_INDEX_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="SnapshotsIndexTableName") | .OutputValue')
SCHEMA_REGISTRY_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="SchemaRegistryTableName") | .OutputValue')
CRITICAL_FIELD_REGISTRY_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="CriticalFieldRegistryTableName") | .OutputValue')
LEDGER_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="LedgerTableName") | .OutputValue')
CACHE_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="CacheTableName") | .OutputValue')
TENANTS_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="TenantsTableName") | .OutputValue')
ACCOUNTS_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="AccountsTableName") | .OutputValue')
SIGNALS_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="SignalsTableName") | .OutputValue')
METHODOLOGY_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="MethodologyTableName") | .OutputValue')
ASSESSMENT_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="AssessmentTableName") | .OutputValue')
IDENTITIES_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="IdentitiesTableName") | .OutputValue')
ACCOUNT_POSTURE_STATE_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="AccountPostureStateTableName") | .OutputValue')
GRAPH_MATERIALIZATION_STATUS_TABLE_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="GraphMaterializationStatusTableName") | .OutputValue')
NEPTUNE_CLUSTER_ENDPOINT_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="NeptuneClusterEndpoint") | .OutputValue')
NEPTUNE_CLUSTER_PORT_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="NeptuneClusterPort") | .OutputValue')
VPC_ID_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="VpcId") | .OutputValue')
NEPTUNE_SUBNET_IDS_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="NeptuneSubnetIds") | .OutputValue')
NEPTUNE_SUBNET_ID_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="NeptuneSubnetId") | .OutputValue')
AGENT_ROLE_ARN_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="AgentRoleArn") | .OutputValue')
USER_POOL_ID_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="UserPoolId") | .OutputValue')
USER_POOL_CLIENT_ID_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="UserPoolClientId") | .OutputValue')
DECISION_API_URL_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="DecisionApiUrl") | .OutputValue')
DECISION_API_KEY_ID_OUTPUT=$(echo "$STACK_OUTPUTS" | jq -r '.[] | select(.OutputKey=="DecisionApiKeyId") | .OutputValue')

# Retrieve API key value (required for API calls - API Gateway needs the actual key value, not just ID)
if [ -n "$DECISION_API_KEY_ID_OUTPUT" ] && [ "$DECISION_API_KEY_ID_OUTPUT" != "null" ]; then
  echo "Retrieving API key value..."
  DECISION_API_KEY_VALUE=$(aws apigateway get-api-key \
    --api-key "$DECISION_API_KEY_ID_OUTPUT" \
    --include-value \
    --region "$AWS_REGION" \
    --query 'value' \
    --output text \
    --profile $CDK_PROFILE \
    --no-cli-pager 2>/dev/null || echo "")
  
  if [ -z "$DECISION_API_KEY_VALUE" ]; then
    echo "âš ï¸  Warning: Could not retrieve API key value. You may need to retrieve it manually."
  fi
else
  DECISION_API_KEY_VALUE=""
fi

# Use stack outputs (preferred) or fall back to .env.local values
EVIDENCE_LEDGER_BUCKET=${EVIDENCE_LEDGER_BUCKET_OUTPUT:-$EVIDENCE_LEDGER_BUCKET}
WORLD_STATE_SNAPSHOTS_BUCKET=${WORLD_STATE_SNAPSHOTS_BUCKET_OUTPUT:-$WORLD_STATE_SNAPSHOTS_BUCKET}
SCHEMA_REGISTRY_BUCKET=${SCHEMA_REGISTRY_BUCKET_OUTPUT:-$SCHEMA_REGISTRY_BUCKET}
ARTIFACTS_BUCKET=${ARTIFACTS_BUCKET_OUTPUT:-$ARTIFACTS_BUCKET}
LEDGER_ARCHIVES_BUCKET=${LEDGER_ARCHIVES_BUCKET_OUTPUT:-$LEDGER_ARCHIVES_BUCKET}

# Create .env file with stack outputs
cat > .env << EOF
# Autonomous Revenue Decision Loop Configuration
# Generated by deploy script on $(date)

# AWS Configuration
AWS_REGION=$AWS_REGION
AWS_PROFILE=$CDK_PROFILE

# Environment
NODE_ENV=$DEPLOYMENT_ENV

# S3 Buckets (World Model)
EVIDENCE_LEDGER_BUCKET=$EVIDENCE_LEDGER_BUCKET
WORLD_STATE_SNAPSHOTS_BUCKET=$WORLD_STATE_SNAPSHOTS_BUCKET
SCHEMA_REGISTRY_BUCKET=$SCHEMA_REGISTRY_BUCKET
ARTIFACTS_BUCKET=$ARTIFACTS_BUCKET
LEDGER_ARCHIVES_BUCKET=$LEDGER_ARCHIVES_BUCKET

# EventBridge
EVENT_BUS_NAME=$EVENT_BUS_NAME

# DynamoDB Tables (World Model)
WORLD_STATE_TABLE_NAME=$WORLD_STATE_TABLE_OUTPUT
EVIDENCE_INDEX_TABLE_NAME=$EVIDENCE_INDEX_TABLE_OUTPUT
SNAPSHOTS_INDEX_TABLE_NAME=$SNAPSHOTS_INDEX_TABLE_OUTPUT
SCHEMA_REGISTRY_TABLE_NAME=$SCHEMA_REGISTRY_TABLE_OUTPUT
CRITICAL_FIELD_REGISTRY_TABLE_NAME=$CRITICAL_FIELD_REGISTRY_TABLE_OUTPUT

# DynamoDB Tables (Application)
LEDGER_TABLE_NAME=$LEDGER_TABLE_OUTPUT
CACHE_TABLE_NAME=$CACHE_TABLE_OUTPUT
TENANTS_TABLE_NAME=$TENANTS_TABLE_OUTPUT
ACCOUNTS_TABLE_NAME=$ACCOUNTS_TABLE_OUTPUT
SIGNALS_TABLE_NAME=$SIGNALS_TABLE_OUTPUT

# DynamoDB Tables (Methodology)
METHODOLOGY_TABLE_NAME=$METHODOLOGY_TABLE_OUTPUT
ASSESSMENT_TABLE_NAME=$ASSESSMENT_TABLE_OUTPUT

# DynamoDB Tables (Identity)
IDENTITIES_TABLE_NAME=$IDENTITIES_TABLE_OUTPUT

# DynamoDB Tables (Phase 2)
ACCOUNT_POSTURE_STATE_TABLE_NAME=$ACCOUNT_POSTURE_STATE_TABLE_OUTPUT
GRAPH_MATERIALIZATION_STATUS_TABLE_NAME=$GRAPH_MATERIALIZATION_STATUS_TABLE_OUTPUT

# Neptune (Phase 2)
NEPTUNE_CLUSTER_ENDPOINT=$NEPTUNE_CLUSTER_ENDPOINT_OUTPUT
NEPTUNE_CLUSTER_PORT=$NEPTUNE_CLUSTER_PORT_OUTPUT

# VPC Configuration (for test runner setup)
VPC_ID=$VPC_ID_OUTPUT
NEPTUNE_SUBNET_IDS=$NEPTUNE_SUBNET_IDS_OUTPUT
NEPTUNE_SUBNET_ID=$NEPTUNE_SUBNET_ID_OUTPUT

# IAM Roles
AGENT_ROLE_ARN=$AGENT_ROLE_ARN_OUTPUT

# Cognito
USER_POOL_ID=$USER_POOL_ID_OUTPUT
USER_POOL_CLIENT_ID=$USER_POOL_CLIENT_ID_OUTPUT

# Phase 3: Decision API
DECISION_API_URL=$DECISION_API_URL_OUTPUT
DECISION_API_KEY_ID=$DECISION_API_KEY_ID_OUTPUT
DECISION_API_KEY=$DECISION_API_KEY_VALUE

# Logging
LOG_LEVEL=$LOG_LEVEL
EOF

echo "Environment variables saved to .env file"

echo ""
echo "ðŸŽ‰ Autonomous Revenue Decision Loop deployment complete!"
echo ""
echo "ðŸ“Š Stack: CCNativeStack"
echo "ðŸŒ Region: $AWS_REGION"
echo "ðŸ”§ Environment: $DEPLOYMENT_ENV"
echo ""
echo "ðŸ“¦ S3 Buckets (World Model):"
echo "   Evidence Ledger: $EVIDENCE_LEDGER_BUCKET"
echo "   World State Snapshots: $WORLD_STATE_SNAPSHOTS_BUCKET"
echo "   Schema Registry: $SCHEMA_REGISTRY_BUCKET"
echo "   Artifacts: $ARTIFACTS_BUCKET"
echo "   Ledger Archives: $LEDGER_ARCHIVES_BUCKET"
echo ""
echo "ðŸ“¡ EventBridge:"
echo "   Event Bus: $EVENT_BUS_NAME"
echo ""
echo "ðŸ“‹ DynamoDB Tables (configured in CDK):"
echo "   - cc-native-accounts"
echo "   - cc-native-signals"
echo "   - cc-native-tool-runs"
echo "   - cc-native-approval-requests"
echo "   - cc-native-action-queue"
echo "   - cc-native-policy-config"
echo "   - cc-native-ledger"
echo "   - cc-native-cache"
echo "   - cc-native-tenants"
echo "   - cc-native-world-state"
echo "   - cc-native-evidence-index"
echo "   - cc-native-snapshots-index"
echo "   - cc-native-schema-registry"
echo "   - cc-native-critical-field-registry"
echo "   - cc-native-methodology"
echo "   - cc-native-assessment"
echo ""
echo "ðŸ“ Configuration saved to .env file"
echo ""
echo "ðŸ§ª Next Steps:"
echo "   1. Review .env file for configuration"
echo "   2. Start implementing Phase 0 services"
echo "   3. Run integration tests"
echo ""
